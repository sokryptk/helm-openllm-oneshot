{{ .Release.Name }} deployed successfully.

Model: {{ .Values.model.id }}
Backend: {{ .Values.model.backend }}

{{- if eq .Values.service.type "LoadBalancer" }}

Get endpoint:
  kubectl get svc {{ include "openllm-oneshot.fullname" . }} -n {{ .Release.Namespace }} -o jsonpath='{.status.loadBalancer.ingress[0].ip}'

{{- else if eq .Values.service.type "NodePort" }}

Get endpoint:
  export NODE_PORT=$(kubectl get svc {{ include "openllm-oneshot.fullname" . }} -n {{ .Release.Namespace }} -o jsonpath='{.spec.ports[0].nodePort}')
  export NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[0].address}')
  echo $NODE_IP:$NODE_PORT

{{- else }}

Port-forward:
  kubectl port-forward svc/{{ include "openllm-oneshot.fullname" . }} 3000:{{ .Values.service.port }} -n {{ .Release.Namespace }}

{{- end }}

Test:
  curl http://<endpoint>/v1/chat/completions -H "Content-Type: application/json" \
    -d '{"model":"{{ .Values.model.id }}","messages":[{"role":"user","content":"hi"}]}'
